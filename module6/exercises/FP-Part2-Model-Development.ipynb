{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model Development\n",
    "\n",
    "In this part, we develop three unique pipelines for predicting backorder. We use the smart sample from Part I to fit and evaluate these pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the smart sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reload your smart sampling from local file \n",
    "# ----------------------------------\n",
    "\n",
    "df = pd.read_csv('sample-data-v1.csv')\n",
    "\n",
    "# Getting rid of the first column which was saved as the row in the csv\n",
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>644.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>1569.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>921.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   national_inv  forecast_3_month  forecast_6_month  forecast_9_month  \\\n",
       "0           1.0               0.0               0.0               0.0   \n",
       "1          80.0             644.0            1091.0            1569.0   \n",
       "2          98.0               0.0               0.0               0.0   \n",
       "3          20.0               0.0               0.0               0.0   \n",
       "4         202.0             224.0             504.0             770.0   \n",
       "\n",
       "   sales_1_month  sales_3_month  sales_6_month  sales_9_month  \\\n",
       "0            0.0            0.0            0.0            0.0   \n",
       "1          210.0          616.0          921.0         1338.0   \n",
       "2            1.0            3.0            7.0           12.0   \n",
       "3            1.0            1.0            4.0           12.0   \n",
       "4           88.0          272.0          585.0          842.0   \n",
       "\n",
       "   potential_issue  pieces_past_due  perf_6_month_avg  perf_12_month_avg  \\\n",
       "0                0              0.0              0.70               0.78   \n",
       "1                0              0.0              1.00               0.99   \n",
       "2                0              0.0              0.79               0.78   \n",
       "3                0              0.0              0.47               0.39   \n",
       "4                0              0.0              0.33               0.32   \n",
       "\n",
       "   deck_risk  oe_constraint  ppap_risk  stop_auto_buy  rev_stop  \\\n",
       "0          0              0          0              1         0   \n",
       "1          0              0          0              1         0   \n",
       "2          0              0          0              1         0   \n",
       "3          0              0          0              1         0   \n",
       "4          0              0          0              1         0   \n",
       "\n",
       "   went_on_backorder  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>national_inv</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>sales_9_month</th>\n",
       "      <th>potential_issue</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22581</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>4388.0</td>\n",
       "      <td>4388.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22582</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22583</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22584</th>\n",
       "      <td>6.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22585</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       national_inv  forecast_3_month  forecast_6_month  forecast_9_month  \\\n",
       "22581           0.0            3454.0            4388.0            4388.0   \n",
       "22582           5.0               3.0               3.0               9.0   \n",
       "22583          -1.0              73.0             114.0             172.0   \n",
       "22584           6.0              61.0              61.0              85.0   \n",
       "22585           0.0               4.0               5.0               7.0   \n",
       "\n",
       "       sales_1_month  sales_3_month  sales_6_month  sales_9_month  \\\n",
       "22581            1.0            1.0            1.0            1.0   \n",
       "22582            1.0            7.0           10.0           13.0   \n",
       "22583           10.0           55.0          109.0          171.0   \n",
       "22584            9.0           24.0           75.0          136.0   \n",
       "22585            1.0            4.0            4.0            5.0   \n",
       "\n",
       "       potential_issue  pieces_past_due  perf_6_month_avg  perf_12_month_avg  \\\n",
       "22581                0              0.0              0.83               0.86   \n",
       "22582                0              0.0              0.34               0.53   \n",
       "22583                0              7.0              0.37               0.54   \n",
       "22584                0              0.0              0.44               0.64   \n",
       "22585                0              0.0              0.78               0.78   \n",
       "\n",
       "       deck_risk  oe_constraint  ppap_risk  stop_auto_buy  rev_stop  \\\n",
       "22581          1              0          0              1         0   \n",
       "22582          0              0          1              1         0   \n",
       "22583          0              0          0              1         0   \n",
       "22584          0              0          1              1         0   \n",
       "22585          0              0          0              1         0   \n",
       "\n",
       "       went_on_backorder  \n",
       "22581                  1  \n",
       "22582                  1  \n",
       "22583                  1  \n",
       "22584                  1  \n",
       "22585                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize/standardize the data if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of the dataset\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(df)\n",
    "\n",
    "df_s = scaler.transform(df)\n",
    "\n",
    "# Normalization of the dataset\n",
    "\n",
    "df_sn = preprocessing.normalize(df_s, axis = 0, norm='l2')\n",
    "\n",
    "df_sn = pd.DataFrame(df_sn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000457</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000431</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.006654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000280</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.001513</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.006654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.006654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000414</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.006654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>-0.00329</td>\n",
       "      <td>-0.000147</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>-0.006654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.000457 -0.000571 -0.000555 -0.000541 -0.000431 -0.000454 -0.000460   \n",
       "1 -0.000280  0.001869  0.001764  0.001755  0.001922  0.001986  0.001513   \n",
       "2 -0.000240 -0.000571 -0.000555 -0.000541 -0.000420 -0.000443 -0.000445   \n",
       "3 -0.000414 -0.000571 -0.000555 -0.000541 -0.000420 -0.000450 -0.000451   \n",
       "4 -0.000008  0.000278  0.000516  0.000586  0.000555  0.000623  0.000793   \n",
       "\n",
       "         7         8         9         10        11       12        13  \\\n",
       "0 -0.000359 -0.000332 -0.000497  0.001655  0.001615 -0.00329 -0.000147   \n",
       "1  0.000993 -0.000332 -0.000497  0.001740  0.001676 -0.00329 -0.000147   \n",
       "2 -0.000347 -0.000332 -0.000497  0.001680  0.001615 -0.00329 -0.000147   \n",
       "3 -0.000347 -0.000332 -0.000497  0.001590  0.001501 -0.00329 -0.000147   \n",
       "4  0.000492 -0.000332 -0.000497  0.001550  0.001480 -0.00329 -0.000147   \n",
       "\n",
       "         14        15        16        17  \n",
       "0 -0.002663  0.001353 -0.000099 -0.006654  \n",
       "1 -0.002663  0.001353 -0.000099 -0.006654  \n",
       "2 -0.002663  0.001353 -0.000099 -0.006654  \n",
       "3 -0.002663  0.001353 -0.000099 -0.006654  \n",
       "4 -0.002663  0.001353 -0.000099 -0.006654  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using the standardized data here but may come back to it.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1:],\n",
    "                                                    test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline\n",
    "\n",
    "In this section, we design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a model\n",
    "\n",
    "We are free to use any of the models that we learned in the past or use new models. \n",
    "\n",
    "* It is difficult to fit an anomaly detection method in the sklearn pipeline without writing custom codes. For simplicity, we avoid fitting an anomaly detection method within a pipeline. So we can create the workflow in two steps. \n",
    "    * Step I: fit an outlier with the training set\n",
    "    * Step II: define a pipeline using a feature selection and a classification method. Then cross-validate this pipeline using the training data without outliers. \n",
    "        * Note: if your smart sample is somewhat imbalanced, you might want to change the scoring method in GridSearchCV (see the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)).\n",
    "\n",
    "* Once we fit the pipeline, we identify the best model and give an unbiased evaluation using the test set that we created in Part II. For unbiased evaluation we report confusion matrix, precision, recall, f1-score, accuracy, and other measures if you like. \n",
    "\n",
    "(Optional) Those who are interested in writing custom codes for adding an outlier detection method into the sklearn pipeline, please follow this discussion [thread](https://stackoverflow.com/questions/52346725/can-i-add-outlier-detection-and-removal-to-scikit-learn-pipeline). \n",
    "\n",
    "\n",
    "**Note:** <span style='background:yellow'>We will be using Grid Search to find the optimal parameters of the pipelines.</span>\n",
    "\n",
    "You can add more notebook cells or import any Python modules as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif, f_regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 1st pipeline \n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation\n",
    "  \n",
    "Add cells as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envelop function code\n",
    "\n",
    "def elliptic_envelope_session(X, y):\n",
    "    # Fit envelope\n",
    "    envelope = EllipticEnvelope(support_fraction=1, contamination=0.2).fit(X)\n",
    "\n",
    "    # Create an boolean indexing array to pick up outliers\n",
    "    outliers = envelope.predict(X)==-1\n",
    "\n",
    "    # Re-slice X,y into a cleaned dataset with outliers excluded\n",
    "    X_clean = X[~outliers]\n",
    "    y_clean = y[~outliers]\n",
    "    return X_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E201)\n",
    "# ----------------------------------\n",
    "\n",
    "# Elliptic Envelope for pipeline 1\n",
    "\n",
    "X_train_env, y_train_env = elliptic_envelope_session(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                       ('PCA', PCA()), ('SVC', SVC())]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'PCA__n_components': [5, 10],\n",
       "                         'SVC__C': [1000.0, 5000.0], 'SVC__kernel': ['rbf']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E202)\n",
    "# ----------------------------------\n",
    "\n",
    "# Using PCA. Set components to 5/10 to start as we only have 16 predictor variables\n",
    "\n",
    "param_grid = {'PCA__n_components': [5, 10],\n",
    "              'SVC__C': [1e3, 5e3],        \n",
    "              'SVC__kernel': ['rbf']}\n",
    "\n",
    "# Define the pipeline (P102)\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('PCA', PCA()),\n",
    "    ('SVC', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "model_grid_1 = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=5)\n",
    "model_grid_1.fit(X_train_env, y_train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', StandardScaler()), ('PCA', PCA(n_components=10)),\n",
      "                ('SVC', SVC(C=5000.0))])\n"
     ]
    }
   ],
   "source": [
    "print(model_grid_1.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_grid_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2263\n",
      "           1       0.86      0.73      0.79      2255\n",
      "\n",
      "    accuracy                           0.81      4518\n",
      "   macro avg       0.81      0.80      0.80      4518\n",
      "weighted avg       0.81      0.81      0.80      4518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E203)\n",
    "# ----------------------------------\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E204)\n",
    "# ---------------------------------------------\n",
    "\n",
    "According to the best params:\n",
    "PCA = 10 components\n",
    "SVC = C=5000.00\n",
    "\n",
    "Both parameters were on the high end of this pipeline\n",
    "\n",
    "f1-score for this model = 0.80 \n",
    "Overall this pipeline appears reletively accurate at prediction backorder cases\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 2nd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means function code\n",
    "\n",
    "def kmeans_session(X, y):\n",
    "    # run k-means clustering\n",
    "    km_clusters = KMeans(n_clusters=3, algorithm=\"full\").fit_predict(X, y)\n",
    "    \n",
    "    # create cluster distribution, this time they are in tuples so we can sort easily\n",
    "    dist_clusters = ((np.sum(km_clusters==z), z) for z in np.unique(km_clusters))\n",
    "    \n",
    "    # sort clusters descendingly by number of data entries in cluster\n",
    "    dist_clusters = sorted(dist_clusters, reverse = True)\n",
    "    \n",
    "    # find out the cluster with max number of data entries\n",
    "    max_cluster = dist_clusters[0][1]\n",
    "\n",
    "    # select data in max_cluster as inliers\n",
    "    inliers = km_clusters == max_cluster\n",
    "    \n",
    "    return X[inliers], y[inliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E205)\n",
    "# ----------------------------------\n",
    "\n",
    "X_train_km, y_train_km = elliptic_envelope_session(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                       ('FactorAnalysis', FactorAnalysis()),\n",
       "                                       ('GaussianNB', GaussianNB())]),\n",
       "             n_jobs=5, param_grid={'FactorAnalysis__n_components': [5, 10]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E206)\n",
    "# ----------------------------------\n",
    "\n",
    "# Use FactorAnalysis and GaussianNB\n",
    "\n",
    "param_grid = {'FactorAnalysis__n_components': [5, 10]}\n",
    "\n",
    "# Define the pipeline (P102)\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('FactorAnalysis', FactorAnalysis()),\n",
    "    ('GaussianNB', GaussianNB())\n",
    "])\n",
    "\n",
    "model_grid_2 = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=5)\n",
    "model_grid_2.fit(X_train_km, y_train_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('FactorAnalysis', FactorAnalysis(n_components=10)),\n",
      "                ('GaussianNB', GaussianNB())])\n"
     ]
    }
   ],
   "source": [
    "print(model_grid_2.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model_grid_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65      2263\n",
      "           1       0.65      0.74      0.69      2255\n",
      "\n",
      "    accuracy                           0.67      4518\n",
      "   macro avg       0.68      0.67      0.67      4518\n",
      "weighted avg       0.68      0.67      0.67      4518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E207)\n",
    "# ----------------------------------\n",
    "\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "For this pipeline, we used Factor Analysis which took less components than PCA. \n",
    "The GaussianNB classifier also did not take additional parameters.\n",
    "\n",
    "Comparing the 2 models, this one performed significantly less effective as the model 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 3rd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For the final model I will use:\n",
    "\n",
    "local_outlier\n",
    "ANOVA with F-value based feature selection\n",
    "LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Outlier function\n",
    "\n",
    "def local_outlier_factor_session(X, y):\n",
    "    lof_labels = LocalOutlierFactor(n_neighbors=10).fit_predict(X, y)\n",
    "    inliers = lof_labels == 1 # select inliers\n",
    "    return X[inliers], y[inliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E209)\n",
    "# ----------------------------------\n",
    "\n",
    "X_train_lo, y_train_lo = local_outlier_factor_session(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:301: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2007: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scale', StandardScaler()),\n",
       "                                       ('SKB',\n",
       "                                        SelectKBest(k=5,\n",
       "                                                    score_func=<function f_regression at 0x7f326baed9d8>)),\n",
       "                                       ('LR', LogisticRegression())]),\n",
       "             n_jobs=5, param_grid={'LR__max_iter': [500, 1000]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E210)\n",
    "# ----------------------------------\n",
    "\n",
    "param_grid = {'LR__max_iter': [500, 1000]}\n",
    "\n",
    "# Define the pipeline (P102)\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('SKB', SelectKBest(f_regression, k=5)),\n",
    "    ('LR', LogisticRegression())\n",
    "])\n",
    "\n",
    "model_grid_3 = GridSearchCV(pipe, param_grid=param_grid, cv=10, n_jobs=5)\n",
    "model_grid_3.fit(X_train_lo, y_train_lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scale', StandardScaler()),\n",
      "                ('SKB',\n",
      "                 SelectKBest(k=5,\n",
      "                             score_func=<function f_regression at 0x7f326baed9d8>)),\n",
      "                ('LR', LogisticRegression(max_iter=500))])\n"
     ]
    }
   ],
   "source": [
    "print(model_grid_3.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = model_grid_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.46      0.56      2263\n",
      "           1       0.60      0.82      0.69      2255\n",
      "\n",
      "    accuracy                           0.64      4518\n",
      "   macro avg       0.66      0.64      0.63      4518\n",
      "weighted avg       0.66      0.64      0.63      4518\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "\n",
    "print(classification_report(y_test, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E212)\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "This model pipeline performed slightly better than the second model, but still computed worse scores than the model using PCA and SVC. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare these three pipelines and discuss your findings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell (Question #E213)\n",
    "# ----------------------------------\n",
    "\n",
    "\n",
    "I computed 3 different pipelines using the following:\n",
    "\n",
    "1) \n",
    "Elliptic Envelop\n",
    "PCA\n",
    "Support Vector Machine\n",
    "\n",
    "2) \n",
    "K Means\n",
    "Factor Analysis\n",
    "Gaussian NB Classifier\n",
    "\n",
    "3) \n",
    "Local Outlier \n",
    "ANOVA F-vale\n",
    "Logistic Classifier\n",
    "\n",
    "\n",
    "After conducting model and testings on the downsampled data it appeared that pipeline number 1 computed the best results on the dataset. Looking at the classification report pipe 1 produced a much more favorable f-score of 0.8 amongst other metrics. Therefore I will move forward with the model built in part 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the required pipeline/models for Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_one.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(model_grid_1, 'model_one.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_one_best.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the best estimator in its own file\n",
    "\n",
    "joblib.dump(model_grid_1.best_estimator_, 'model_one_best.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have made a few commits so far of this project.  \n",
    "**Definitely make a commit of the notebook now!**  \n",
    "Comment should be: `Final Project, Checkpoint - Pipelines done`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
