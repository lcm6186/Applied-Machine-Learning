{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 \n",
    "# Operationalizing a Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Topics\n",
    " * Building Data Processing Pipelines\n",
    " * Implementing the Machine Learning Workflow\n",
    "\n",
    "![AppliedML_Workflow IMAGE](./images/AppliedML_Workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    " * Please review the Stat/Math content (high dimensional reduction, classification)\n",
    " * Applied ML course material, especially Modules 1-5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labs &amp; Practices\n",
    "\n",
    "There are no labs in this module. However, the labs and practices in Module 1-5 will be good to review.  \n",
    "**More specifically, _Pipeline_, _Grid Search_, and _Class-Imbalance-Problem_ lessons.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "In this project we develop several machine learning pipelines for predicting product backorder. The dataset we will be using for training pipelines has class-imbalance issue. Please see the preprocessing notebook (Part I) to learn about the dataset. Here we are presented with two datasets: train and test. Training set will be used in all three parts, but the test set will be only be used in Part 3 for model evaluaiton. \n",
    "\n",
    "![img](./images/train-test.png)\n",
    "\n",
    "\n",
    "#### Part I \n",
    "\n",
    "In this part we curate the training set. To deal with the class-imbalance problem, we need to sample this training dataset and create a balanced (or roughly balanced) training set. \n",
    "\n",
    "#### Part 2 \n",
    "\n",
    "Given the balanced training set, we will develop three unique pipelines. In each of this pipeline we  remove outliers, perform automated feature selection, and then classify backorder. We will be using gridsearh with cross validataion for fitting the pipeline. \n",
    "\n",
    "In this model development phase we assume that we don't have access to the given test set. So we take the curated training set and create two datasets: train-validation set and test set. We use train-validation set for fitting and fine tuning the pipeline, and employ test set for giving an unbiased evaluation. \n",
    "\n",
    "We compare these pipelines and store the best pipeline. \n",
    "\n",
    "#### Part 3: \n",
    "\n",
    "In Part 3, we retrain the best pipeline with all the balanced training set but use the best model's parameters found in Part 2. So we don't need to do the grid search one again. We then evaluate this retrained pipeline using the given test set (unbiased evaluation). \n",
    "\n",
    "\n",
    "* [Part I - Preprocessing](./exercises/FP-Part1-Preprocessing.ipynb)\n",
    "* [Part II - Model Development](./exercises/FP-Part2-Model-Development.ipynb)\n",
    "* [Part II - Evaluation](./exercises/FP-Part3-Evaluation.ipynb)\n",
    "\n",
    "\n",
    "The notebooks for these three parts are in Module 6 folder. Although Part III belongs to Module 7, we kept it here due to it's dependency on the first two. So you will find Module 7 empty. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting your work\n",
    "\n",
    "#### Steps:\n",
    "  1. Open Terminal in JupyterHub\n",
    "  1. Change into the course folder\n",
    "  1. Stage (Git Add) the module's practive and exercise work   \n",
    "  `git  add    module6/exercises`\n",
    "  1. Create your work snapshot (Git Commit)  \n",
    "  `git   commit   -m   \"Module 6 submission\"`\n",
    "  1. Upload the snapshot to the server (Git Push)  \n",
    "  `git   push`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, you have completed the learning activities for this module!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
