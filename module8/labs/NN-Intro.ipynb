{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Neural Network Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial neuron\n",
    "\n",
    "Recall the concept of a [neuron](https://en.wikipedia.org/wiki/Artificial_neuron) based on its mathematical formula.\n",
    "\n",
    "$$ y_k = \\varphi \\left( \\sum_{j=0}^{m}{w_{kj}x_j} +b_k \\right) $$\n",
    "\n",
    "This is a simple **linear** neuron. If you look closely, you will see the formula for multiple linear regression (if $\\varphi$ is removed)! If $\\varphi$ is a sigmoid funciton then it becomes the formula for losistic regression. \n",
    "\n",
    "PyTorch, as well as other NN packages, support numerous types of neurons. Typically, neurons are composed into layers, and a single layer has only a single type of neuron.\n",
    "\n",
    "In this lab, we devlop linear regression and logistic regression models with neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools \n",
    "\n",
    "**PyTorch**: In this lab, we are going to drill down into some neural network basics using the PyTorch package.\n",
    "\n",
    "**What is PyTorch?**\n",
    "\n",
    "From PyTorch official [site](https://pytorch.org/): \n",
    "\n",
    "> PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing, primarily developed by Facebook's AI Research lab. It is free and open-source software released under the Modified BSD license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale, LabelBinarizer, StandardScaler, Normalizer\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "# Random seed for numpy\n",
    "np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Multiple Regression Model using Neural Network\n",
    "\n",
    "Let's explore the Boston housing dataset which is used in a regression setting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_boston()\n",
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df['Price'] = dataset.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       Price  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization/Normalization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>0.130238</td>\n",
       "      <td>0.008170</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.591265</td>\n",
       "      <td>0.030562</td>\n",
       "      <td>0.792814</td>\n",
       "      <td>0.009948</td>\n",
       "      <td>0.047940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.166966</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.004232</td>\n",
       "      <td>0.512112</td>\n",
       "      <td>0.037668</td>\n",
       "      <td>0.839907</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.045709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001004</td>\n",
       "      <td>0.015379</td>\n",
       "      <td>0.130778</td>\n",
       "      <td>0.010632</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.517974</td>\n",
       "      <td>0.038099</td>\n",
       "      <td>0.840809</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>0.074272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>0.100257</td>\n",
       "      <td>0.013270</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>0.485964</td>\n",
       "      <td>0.040935</td>\n",
       "      <td>0.863856</td>\n",
       "      <td>0.006436</td>\n",
       "      <td>0.073114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.015539</td>\n",
       "      <td>0.117842</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.482675</td>\n",
       "      <td>0.040658</td>\n",
       "      <td>0.862945</td>\n",
       "      <td>0.011589</td>\n",
       "      <td>0.078707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS  CHAS       NOX        RM       AGE       DIS  \\\n",
       "0  0.000013  0.035955  0.004614   0.0  0.001075  0.013134  0.130238  0.008170   \n",
       "1  0.000058  0.000000  0.014961   0.0  0.000992  0.013588  0.166966  0.010511   \n",
       "2  0.000058  0.000000  0.015133   0.0  0.001004  0.015379  0.130778  0.010632   \n",
       "3  0.000071  0.000000  0.004772   0.0  0.001003  0.015319  0.100257  0.013270   \n",
       "4  0.000150  0.000000  0.004740   0.0  0.000996  0.015539  0.117842  0.013181   \n",
       "\n",
       "        RAD       TAX   PTRATIO         B     LSTAT     Price  \n",
       "0  0.001998  0.591265  0.030562  0.792814  0.009948  0.047940  \n",
       "1  0.004232  0.512112  0.037668  0.839907  0.019342  0.045709  \n",
       "2  0.004281  0.517974  0.038099  0.840809  0.008626  0.074272  \n",
       "3  0.006567  0.485964  0.040935  0.863856  0.006436  0.073114  \n",
       "4  0.006523  0.482675  0.040658  0.862945  0.011589  0.078707  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = Normalizer()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "df_scaled = pd.DataFrame(data_scaled, columns=list(dataset.feature_names) + ['Price'])\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_scaled.drop('Price', axis=1).to_numpy()\n",
    "y = df_scaled['Price'].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a neural network\n",
    "\n",
    "Now we will construct a basic Neural Network with\n",
    " * One hidden layer fed by 13 input values (as there are 13 features)\n",
    " * One output layer \n",
    " \n",
    "##### Note: The summary will show that we have 16 total learnable parameters:\n",
    "  * 14 for the hidden layer (13 feature values and bias)\n",
    "  * 1 for the output layer (Hidden ($H_0$) and without bias) \n",
    "  \n",
    "\n",
    "<figure>\n",
    "  <img src=\"../images/reg_as_nn.jpg\" width=600 height=400 alt=\"figure alt text\">\n",
    "  <figcaption>\n",
    "      <b>Fig. A neural network for solving muliple regression problem.</b> <!-- can also use <div>, <p>, etc. tags within <figcaption> -->\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary pytorch modules\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model\n",
    "\n",
    "One way to define a neural network in PyTorch is to subclass the `nn.Module` class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRegNN(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        D_in: number of input\n",
    "        \"\"\"\n",
    "        super(MyRegNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(D_in, H) # input to hidden layer\n",
    "        self.layer2 = nn.Linear(H, D_out, bias=False) # input to hidden layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_pred = self.layer1(x)        # h = dot(input,w1) \n",
    "        y_pred = self.layer2(h_pred)   \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an instance of the network class we have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a network with 13 inputs to 1 hidden neurons to one output neuron \n",
    "\n",
    "D_in, H, D_out = X_train.shape[1], 1, 1    \n",
    "\n",
    "net = MyRegNN(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize this model using `summary` function from `torchsummary` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]              14\n",
      "            Linear-2                    [-1, 1]               1\n",
      "================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (X_train.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()   # Mean Squared error loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.3)  \n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Before training the model, we need to convert the pandas/numpy datasets to pytorch's tensor data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors from the train/test set\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better iteration over the train/test sets, there are two handy methods: TensorDataset and DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1  # it is possible to feed more than one istances to the model. \n",
    "# These set of instances is called batch. For simplicity, let's keep one instance per batch\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the mdoel with 100 epochs. The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset. Within an epoch each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. \n",
    "\n",
    "Note: For simplicity we are skipping k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Total Loss: 0.80323 | Avg Loss: 0.00187\n",
      "Epoch 005: | Total Loss: 0.51578 | Avg Loss: 0.00120\n",
      "Epoch 010: | Total Loss: 0.39139 | Avg Loss: 0.00091\n",
      "Epoch 015: | Total Loss: 0.30770 | Avg Loss: 0.00072\n",
      "Epoch 020: | Total Loss: 0.24940 | Avg Loss: 0.00058\n",
      "Epoch 025: | Total Loss: 0.20783 | Avg Loss: 0.00048\n",
      "Epoch 030: | Total Loss: 0.17789 | Avg Loss: 0.00041\n",
      "Epoch 035: | Total Loss: 0.15574 | Avg Loss: 0.00036\n",
      "Epoch 040: | Total Loss: 0.13926 | Avg Loss: 0.00032\n",
      "Epoch 045: | Total Loss: 0.12686 | Avg Loss: 0.00030\n",
      "Epoch 050: | Total Loss: 0.11739 | Avg Loss: 0.00027\n",
      "Epoch 055: | Total Loss: 0.11027 | Avg Loss: 0.00026\n",
      "Epoch 060: | Total Loss: 0.10472 | Avg Loss: 0.00024\n",
      "Epoch 065: | Total Loss: 0.10046 | Avg Loss: 0.00023\n",
      "Epoch 070: | Total Loss: 0.09714 | Avg Loss: 0.00023\n",
      "Epoch 075: | Total Loss: 0.09456 | Avg Loss: 0.00022\n",
      "Epoch 080: | Total Loss: 0.09253 | Avg Loss: 0.00022\n",
      "Epoch 085: | Total Loss: 0.09095 | Avg Loss: 0.00021\n",
      "Epoch 090: | Total Loss: 0.08966 | Avg Loss: 0.00021\n",
      "Epoch 095: | Total Loss: 0.08868 | Avg Loss: 0.00021\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100  # In each epoch, the model iterate over all the instances \n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = net(x)        # Forward pass: get the network output for this instance\n",
    "        l = loss(output, y)    # estimate error for this instance\n",
    "        epoch_loss += l.item() # Aggregate error\n",
    "        optimizer.zero_grad()  # As backward method accumulates gradient, we need to set it to 0\n",
    "        l.backward()           # Backward pass: Estimate gradient \n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch%5)==0:\n",
    "        print(f'Epoch {epoch+0:03}: | Total Loss: {epoch_loss:.5f} | Avg Loss: {epoch_loss/len(train_loader):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()  # notify all the layers that we are in eval mode\n",
    "\n",
    "with torch.no_grad(): \n",
    "    y_test_pred = net(X_test_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.43304415737722446\n",
      "MSE:0.0002304868692226775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(f\"R^2: {r2_score(y_test, y_test_pred.numpy())}\")\n",
    "print(f\"MSE:{mean_squared_error(y_test, y_test_pred.numpy())}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of MSE and R^2, the neural network performed better than the baseline which predicts mean as an output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Logistic Regression Model using Neural Network\n",
    "\n",
    "For this lab, we will use sklearn breast cancer dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  class  \n",
       "0          0.4601                  0.11890      0  \n",
       "1          0.2750                  0.08902      0  \n",
       "2          0.3613                  0.08758      0  \n",
       "3          0.6638                  0.17300      0  \n",
       "4          0.2364                  0.07678      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df['class'] = cancer.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization/Normalization of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>0.440986</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.889462</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.007486</td>\n",
       "      <td>0.055988</td>\n",
       "      <td>0.558619</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.066899</td>\n",
       "      <td>0.824026</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.572276</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012145</td>\n",
       "      <td>0.072545</td>\n",
       "      <td>0.812984</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016325</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>0.110899</td>\n",
       "      <td>0.551922</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037881</td>\n",
       "      <td>0.141333</td>\n",
       "      <td>0.811515</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.065808</td>\n",
       "      <td>0.631774</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.074137</td>\n",
       "      <td>0.767189</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.007925      0.004573        0.054099   0.440986         0.000052   \n",
       "1     0.008666      0.007486        0.055988   0.558619         0.000036   \n",
       "2     0.009367      0.010109        0.061842   0.572276         0.000052   \n",
       "3     0.016325      0.029133        0.110899   0.551922         0.000204   \n",
       "4     0.009883      0.006985        0.065808   0.631774         0.000049   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.000122        0.000132             0.000065       0.000107   \n",
       "1          0.000033        0.000037             0.000030       0.000076   \n",
       "2          0.000076        0.000094             0.000061       0.000098   \n",
       "3          0.000406        0.000345             0.000150       0.000371   \n",
       "4          0.000065        0.000096             0.000051       0.000088   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                0.000035  ...       0.007635         0.081325    0.889462   \n",
       "1                0.000024  ...       0.009862         0.066899    0.824026   \n",
       "2                0.000029  ...       0.012145         0.072545    0.812984   \n",
       "3                0.000139  ...       0.037881         0.141333    0.811515   \n",
       "4                0.000029  ...       0.008120         0.074137    0.767189   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.000071           0.000293         0.000314              0.000117   \n",
       "1          0.000052           0.000079         0.000102              0.000078   \n",
       "2          0.000069           0.000202         0.000214              0.000116   \n",
       "3          0.000300           0.001238         0.000982              0.000368   \n",
       "4          0.000067           0.000100         0.000195              0.000079   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  class  \n",
       "0        0.000203                 0.000052      0  \n",
       "1        0.000116                 0.000038      0  \n",
       "2        0.000172                 0.000042      0  \n",
       "3        0.000949                 0.000247      0  \n",
       "4        0.000115                 0.000037      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('class', axis=1).to_numpy()\n",
    "y = df['class'].to_numpy()\n",
    "\n",
    "scaler = Normalizer()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=list(cancer.feature_names))\n",
    "df_scaled['class'] = y\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df_scaled['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a neural network\n",
    "\n",
    "Now we will construct a basic Neural Network with\n",
    " * One hidden layer fed by 30 input values (as there are 30 features)\n",
    " * One output layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogitNN(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        D_in: number of input\n",
    "        \"\"\"\n",
    "        super(MyLogitNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(D_in, H) # input to hidden layer\n",
    "        self.layer2 = nn.Linear(H, D_out, bias=False) # input to hidden layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_pred = self.layer1(x)        \n",
    "        y_pred = torch.sigmoid(self.layer2(h_pred))   \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an instance of the network class we have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is a network with 13 inputs to 1 hidden neurons to one output neuron \n",
    "\n",
    "D_in, H, D_out = X_train.shape[1], 1, 1    \n",
    "\n",
    "net = MyLogitNN(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize this model using `summary` function from `torchsummary` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]              31\n",
      "            Linear-2                    [-1, 1]               1\n",
      "================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (X_train.shape[1],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = nn.MSELoss()   \n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.3)  \n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Before training the model, we need to convert the pandas/numpy datasets to pytorch's tensor data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors from the train/test set\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better iteration over the train/test sets, there are two handy methods: TensorDataset and DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1  # it is possible to feed more than one istances to the model. \n",
    "# These set of instances is called batch. For simplicity, let's keep one instance per batch\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train the mdoel with 100 epochs. The number of epochs is a hyperparameter that defines the number times that the learning algorithm will work through the entire training dataset. Within an epoch each sample in the training dataset has had an opportunity to update the internal model parameters. An epoch is comprised of one or more batches. \n",
    "\n",
    "Note: For simplicity we are skipping k-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: | Total Loss: 319.79717 | Avg Loss: 0.66211\n",
      "Epoch 005: | Total Loss: 258.50843 | Avg Loss: 0.53521\n",
      "Epoch 010: | Total Loss: 251.01117 | Avg Loss: 0.51969\n",
      "Epoch 015: | Total Loss: 248.16098 | Avg Loss: 0.51379\n",
      "Epoch 020: | Total Loss: 246.24395 | Avg Loss: 0.50982\n",
      "Epoch 025: | Total Loss: 245.33038 | Avg Loss: 0.50793\n",
      "Epoch 030: | Total Loss: 246.11768 | Avg Loss: 0.50956\n",
      "Epoch 035: | Total Loss: 243.98878 | Avg Loss: 0.50515\n",
      "Epoch 040: | Total Loss: 242.69297 | Avg Loss: 0.50247\n",
      "Epoch 045: | Total Loss: 246.09537 | Avg Loss: 0.50951\n",
      "Epoch 050: | Total Loss: 243.81669 | Avg Loss: 0.50480\n",
      "Epoch 055: | Total Loss: 243.91049 | Avg Loss: 0.50499\n",
      "Epoch 060: | Total Loss: 243.85692 | Avg Loss: 0.50488\n",
      "Epoch 065: | Total Loss: 243.87989 | Avg Loss: 0.50493\n",
      "Epoch 070: | Total Loss: 243.46901 | Avg Loss: 0.50408\n",
      "Epoch 075: | Total Loss: 242.89966 | Avg Loss: 0.50290\n",
      "Epoch 080: | Total Loss: 243.53383 | Avg Loss: 0.50421\n",
      "Epoch 085: | Total Loss: 245.68934 | Avg Loss: 0.50867\n",
      "Epoch 090: | Total Loss: 245.67810 | Avg Loss: 0.50865\n",
      "Epoch 095: | Total Loss: 246.38856 | Avg Loss: 0.51012\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100  # In each epoch, the model iterate over all the instances \n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        output = net(x)        # Forward pass: get the network output for this instance\n",
    "        l = loss(output, y)    # estimate error for this instance\n",
    "        epoch_loss += l.item() # Aggregate error\n",
    "        optimizer.zero_grad()  # As backward method accumulates gradient, we need to set it to 0\n",
    "        l.backward()           # Backward pass: Estimate gradient \n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch%5)==0:\n",
    "        print(f'Epoch {epoch+0:03}: | Total Loss: {epoch_loss:.5f} | Avg Loss: {epoch_loss/len(train_loader):.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9483e-01],\n",
       "        [1.2563e-02],\n",
       "        [3.5066e-11],\n",
       "        [3.6112e-02],\n",
       "        [1.1795e-13]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()  # notify all the layers that we are in eval mode\n",
    "\n",
    "with torch.no_grad(): \n",
    "    y_test_pred = net(X_test_tensor)\n",
    "    \n",
    "y_test_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_class = torch.round(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[26  1]\n",
      " [14 45]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.96      0.78        27\n",
      "           1       0.98      0.76      0.86        59\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        86\n",
      "   macro avg       0.81      0.86      0.82        86\n",
      "weighted avg       0.88      0.83      0.83        86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(f\"Confusion Matrix:\\n {confusion_matrix(y_test, y_test_pred_class.numpy())}\")\n",
    "print(f\"Classification Report:\\n {classification_report(y_test, y_test_pred_class.numpy())}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we learned a step-by-step process for developing neural networks for solving regression and classification problems. These are elementary neural networks, but the process is similar even if our network architecture has more layers/neurons.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PyTorch API and helpful links\n",
    "\n",
    " * Layers: https://pytorch.org/docs/stable/nn.html\n",
    " * Loss / Loss Functions : [link1](https://medium.com/udacity-pytorch-challengers/a-brief-overview-of-loss-functions-in-pytorch-c0ddb78068f7) [link2](https://neptune.ai/blog/pytorch-loss-functions)\n",
    " * Optimizers (learning algorithm) : https://pytorch.org/docs/stable/optim.html\n",
    " * Neuron Activation Functions : https://towardsdatascience.com/understanding-pytorch-activation-functions-the-maths-and-algorithms-part-1-7d8ade494cee\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please restart the kernel and clear all output, then play around with parameters or add cells and create additional notebooks\n",
    "\n",
    "# Save your notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
